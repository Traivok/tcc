{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for YOLO Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path setup - Adjust the root directory accordingly\n",
    "cwd = os.getcwd()\n",
    "project_path = os.path.join(cwd, \"..\", \"..\")\n",
    "dataset_path = os.path.join(project_path, \"data\", \"ships_v10i\") # Replace with your dataset folder\n",
    "splits = ['train', 'valid', 'test']\n",
    "\n",
    "date_str = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "experiments_path = os.path.join(project_path, \"experiments\", date_str)\n",
    "os.makedirs(experiments_path, exist_ok=True)\n",
    "eda_summary = {}  # Dictionary to store all EDA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all image and label paths from a given split\n",
    "def get_image_label_paths(split):\n",
    "    images_dir = os.path.join(dataset_path, split, \"images\")\n",
    "    labels_dir = os.path.join(dataset_path, split, \"labels\")\n",
    "    image_files = sorted([os.path.join(images_dir, f) for f in os.listdir(images_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "    label_files = sorted([os.path.join(labels_dir, f) for f in os.listdir(labels_dir) if f.endswith('.txt')])\n",
    "    return image_files, label_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store data\n",
    "split_data = {}\n",
    "for split in splits:\n",
    "    image_files, label_files = get_image_label_paths(split)\n",
    "    split_data[split] = {'images': image_files, 'labels': label_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Counting the number of images and labels per split\n",
    "image_label_stats = {}\n",
    "for split in splits:\n",
    "    image_label_stats[split] = {\n",
    "        'num_images': len(split_data[split]['images']),\n",
    "        'num_labels': len(split_data[split]['labels'])\n",
    "    }\n",
    "eda_summary['image_label_stats'] = image_label_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 2327/2327 [00:06<00:00, 366.29it/s]\n",
      "Processing valid: 100%|██████████| 521/521 [00:01<00:00, 346.71it/s]\n",
      "Processing test: 100%|██████████| 417/417 [00:01<00:00, 366.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2. Bounding box statistics\n",
    "def parse_yolo_label(label_path):\n",
    "    with open(label_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return [list(map(float, line.strip().split()[1:])) for line in lines]  # Ignore class ID\n",
    "\n",
    "def analyze_bounding_boxes(split):\n",
    "    all_bboxes = []\n",
    "    bboxes_per_image = []\n",
    "    for label_path in tqdm(split_data[split]['labels'], desc=f\"Processing {split}\"):\n",
    "        bboxes = parse_yolo_label(label_path)\n",
    "        bboxes_per_image.append(len(bboxes))\n",
    "        all_bboxes.extend(bboxes)\n",
    "    bboxes_df = pd.DataFrame(all_bboxes, columns=['x_center', 'y_center', 'width', 'height'])\n",
    "    return {\n",
    "        'mean_bboxes_per_image': np.mean(bboxes_per_image),\n",
    "        'median_bboxes_per_image': np.median(bboxes_per_image),\n",
    "        'mean_bbox_size': bboxes_df[['width', 'height']].mean().values.tolist(),\n",
    "        'median_bbox_size': bboxes_df[['width', 'height']].median().values.tolist()\n",
    "    }\n",
    "\n",
    "bbox_stats = {split: analyze_bounding_boxes(split) for split in splits}\n",
    "eda_summary['bbox_stats'] = bbox_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing train: 100%|██████████| 2320/2320 [00:16<00:00, 143.17it/s]\n",
      "Analyzing valid: 100%|██████████| 521/521 [00:03<00:00, 157.51it/s]\n",
      "Analyzing test: 100%|██████████| 417/417 [00:02<00:00, 143.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# 3. Image size statistics\n",
    "def analyze_image_sizes(split):\n",
    "    resolutions = []\n",
    "    for image_path in tqdm(split_data[split]['images'], desc=f\"Analyzing {split}\"):\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            resolutions.append(img.shape[:2])  # Height, Width\n",
    "    resolutions = np.array(resolutions)\n",
    "    return {\n",
    "        'mean_resolution': np.mean(resolutions, axis=0).tolist(),\n",
    "        'median_resolution': np.median(resolutions, axis=0).tolist()\n",
    "    }\n",
    "\n",
    "image_stats = {split: analyze_image_sizes(split) for split in splits}\n",
    "eda_summary['image_stats'] = image_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA summary saved to /mnt/c/Users/Ricardo/Documents/Development/tcc-1/tcc/autoencoders/../../experiments/2024-12-17_20-05-54/eda_summary.md\n"
     ]
    }
   ],
   "source": [
    "# 4. Save EDA summary to Markdown file\n",
    "eda_summary_md_path = os.path.join(experiments_path, 'eda_summary.md')\n",
    "\n",
    "\n",
    "def dict_to_markdown(eda_summary):\n",
    "    md_content = \"# Exploratory Data Analysis Summary\\n\\n\"\n",
    "    for section, stats in eda_summary.items():\n",
    "        md_content += f\"## {section.replace('_', ' ').title()}\\n\\n\"\n",
    "        if isinstance(stats, dict):\n",
    "            for split, split_stats in stats.items():\n",
    "                md_content += f\"### {split.capitalize()}\\n\\n\"\n",
    "                for key, value in split_stats.items():\n",
    "                    md_content += f\"- **{key.replace('_',\n",
    "                                                     ' ').title()}**: {value}\\n\"\n",
    "                md_content += \"\\n\"\n",
    "        else:\n",
    "            md_content += f\"{stats}\\n\\n\"\n",
    "    return md_content\n",
    "\n",
    "\n",
    "with open(eda_summary_md_path, 'w') as file:\n",
    "    file.write(dict_to_markdown(eda_summary))\n",
    "\n",
    "print(f\"EDA summary saved to {eda_summary_md_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
