{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import cv2\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model, layers, models\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = pathlib.Path(os.getcwd(), \"..\", \"..\").resolve()\n",
    "\n",
    "class Config:\n",
    "    experiments_path = pathlib.Path(os.path.join(base_path, \"experiments\", \"autoencoder\")).resolve()\n",
    "    dataset_path = pathlib.Path(os.path.join(base_path, \"data\", \"categorized_images\")).resolve()\n",
    "    patience = 5\n",
    "    epochs = 1000\n",
    "    batch_size = 8\n",
    "    encoding_dim = 128\n",
    "    imgsz = 128\n",
    "    n_clusters = 4\n",
    "\n",
    "os.makedirs(Config.experiments_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Config.experiments_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(input_shape, encoding_dim):\n",
    "    inputs = tf.keras.Input(shape=input_shape, name=\"encoder_input\")\n",
    "\n",
    "    # Encoder\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "    # Calculate shape before flattening\n",
    "    shape_before_flattening = x.shape[1:]  # (H, W, C)\n",
    "    flattened_dim = int(np.prod(shape_before_flattening))  # Convert to integer\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    encoded = tf.keras.layers.Dense(\n",
    "        encoding_dim, activation=\"relu\", name=\"latent\")(x)\n",
    "\n",
    "    # Decoder\n",
    "    x_dec = tf.keras.layers.Dense(\n",
    "        flattened_dim, activation=\"relu\", name=\"dec_dense\")(encoded)\n",
    "    x_dec = tf.keras.layers.Reshape(shape_before_flattening)(x_dec)\n",
    "    x_dec = tf.keras.layers.Conv2DTranspose(\n",
    "        128, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x_dec)\n",
    "    x_dec = tf.keras.layers.Conv2DTranspose(\n",
    "        64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x_dec)\n",
    "    x_dec = tf.keras.layers.Conv2DTranspose(\n",
    "        32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x_dec)\n",
    "    decoded = tf.keras.layers.Conv2D(\n",
    "        3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x_dec)\n",
    "\n",
    "    autoencoder = tf.keras.Model(inputs, decoded, name=\"autoencoder\")\n",
    "    encoder = tf.keras.Model(inputs, encoded, name=\"encoder\")\n",
    "\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models\n",
    "autoencoder, encoder = build_autoencoder(\n",
    "    input_shape=(Config.imgsz, Config.imgsz, 3), encoding_dim=Config.encoding_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save autoencoder\n",
    "autoencoder.save(os.path.join(Config.experiments_path, \"autoencoder_no_train.keras\"))\n",
    "keras.utils.plot_model(autoencoder, os.path.join(Config.experiments_path, \"autoencoder.png\"), show_shapes=True)\n",
    "keras.utils.plot_model(autoencoder, os.path.join(Config.experiments_path, \"autoencoder_no_shapes.png\"), show_shapes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_tsne_and_clustering(encoder, dataset, n_clusters, experiments_path):\n",
    "    # Extract embeddings using encoder\n",
    "    embeddings = []\n",
    "    for images, _ in dataset.unbatch():\n",
    "        embeddings.append(encoder.predict(images[np.newaxis, ...]))\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "    # Apply TSNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(tsne_embeddings)\n",
    "\n",
    "    # Save embeddings and cluster labels\n",
    "    np.save(os.path.join(experiments_path, \"tsne_embeddings.npy\"), tsne_embeddings)\n",
    "    np.save(os.path.join(experiments_path, \"cluster_labels.npy\"), cluster_labels)\n",
    "\n",
    "    # Plot t-SNE results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_points = tsne_embeddings[cluster_labels == cluster]\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f\"Cluster {cluster}\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.title(\"t-SNE Clustering\")\n",
    "    plt.savefig(os.path.join(experiments_path, \"tsne_clustering.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    # Plot t-SNE results without clustering (just the points)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(tsne_embeddings[:, 0], tsne_embeddings[:, 1], alpha=0.6)\n",
    "    plt.title(\"t-SNE Points without Clustering\")\n",
    "    plt.savefig(os.path.join(experiments_path, \"tsne_points.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    return tsne_embeddings, cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo o modelo\n",
    "autoencoder, encoder = build_autoencoder(\n",
    "    (Config.imgsz, Config.imgsz, 3), Config.encoding_dim)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "tuplify = lambda x, n: (x, ) * n\n",
    "duplify = lambda x: tuplify(x, 2)\n",
    "\n",
    "# Carregando o dataset\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    Config.dataset_path,\n",
    "    labels=None,\n",
    "    image_size=(Config.imgsz, Config.imgsz),\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=True\n",
    ").map(lambda x: duplify(x / 255.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Treinamento com EarlyStopping\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor=\"loss\",  # Monitora a métrica de perda\n",
    "#     patience=Config.patience,\n",
    "#     restore_best_weights=True  # Restaura os pesos da melhor época\n",
    "# )\n",
    "\n",
    "# steps_per_epoch = len(train_dataset) // Config.batch_size\n",
    "\n",
    "# # Treinando o modelo\n",
    "# autoencoder.fit(\n",
    "#     train_dataset.repeat(),\n",
    "#     epochs=Config.epochs,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     callbacks=[early_stopping]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extração de embeddings com progresso usando tqdm\n",
    "# embeddings = []\n",
    "# # Converte para iterador NumPy\n",
    "# dataset_iterator = train_dataset.unbatch().as_numpy_iterator()\n",
    "# total_images = len(list(train_dataset.unbatch()))  # Conta o total de imagens\n",
    "\n",
    "# for image_pair in tqdm(dataset_iterator, total=total_images, desc=\"Extraindo Embeddings\"):\n",
    "#     image = image_pair[0]  # Extrai a imagem (primeiro elemento do par)\n",
    "#     # Adiciona dimensão de batch\n",
    "#     embeddings.append(encoder.predict(image[tf.newaxis, ...], verbose=0))\n",
    "\n",
    "# embeddings = np.vstack(embeddings)\n",
    "\n",
    "# # TSNE e visualização\n",
    "# tsne = TSNE(n_components=2, random_state=42)\n",
    "# tsne_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# # Visualizar t-SNE\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.scatter(tsne_embeddings[:, 0], tsne_embeddings[:, 1], alpha=0.5)\n",
    "# plt.title(\"t-SNE Visualization of Embeddings (Large Category)\")\n",
    "# plt.xlabel(\"t-SNE Component 1\")\n",
    "# plt.ylabel(\"t-SNE Component 2\")\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "\n",
    "# # Imprimindo os pontos do t-SNE\n",
    "# print(\"t-SNE Points:\")\n",
    "# print(tsne_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# # Clusterização com K-Means\n",
    "# n_clusters = 4  # Número de clusters desejado\n",
    "# kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "# cluster_labels = kmeans.fit_predict(tsne_embeddings)\n",
    "\n",
    "# # Visualizar os clusters\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# for cluster in range(n_clusters):\n",
    "#     cluster_points = tsne_embeddings[cluster_labels == cluster]\n",
    "#     plt.scatter(cluster_points[:, 0], cluster_points[:, 1],\n",
    "#                 label=f\"Cluster {cluster}\", alpha=0.6)\n",
    "\n",
    "# # Marcar os centróides\n",
    "# centroids = kmeans.cluster_centers_\n",
    "# plt.scatter(centroids[:, 0], centroids[:, 1], s=200,\n",
    "#             c=\"black\", marker=\"X\", label=\"Centroids\")\n",
    "\n",
    "# # Configurar o gráfico\n",
    "# plt.title(\"t-SNE Clusters with K-Means\")\n",
    "# plt.xlabel(\"t-SNE Component 1\")\n",
    "# plt.ylabel(\"t-SNE Component 2\")\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "\n",
    "# # Exibir as informações dos clusters\n",
    "# for cluster in range(n_clusters):\n",
    "#     print(f\"Cluster {cluster}: {np.sum(cluster_labels == cluster)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cluster_examples(dataset, tsne_embeddings, cluster_labels, n_examples=5):\n",
    "    \"\"\"\n",
    "    Mostra exemplos de imagens pertencentes a cada cluster.\n",
    "    \n",
    "    Args:\n",
    "    - dataset: Dataset original usado para t-SNE (formato (input, input)).\n",
    "    - tsne_embeddings: Embeddings do t-SNE (array de shape (N, 2)).\n",
    "    - cluster_labels: Rótulos dos clusters gerados (array de shape (N,)).\n",
    "    - n_examples: Número de exemplos para mostrar de cada cluster.\n",
    "    \"\"\"\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    # Convertendo o dataset para iterador NumPy\n",
    "    dataset_iterator = dataset.unbatch().as_numpy_iterator()\n",
    "\n",
    "    # Carregar todas as imagens para acesso rápido\n",
    "    # Usar apenas as imagens de entrada\n",
    "    all_images = [pair[0] for pair in dataset_iterator]\n",
    "    all_images = np.array(all_images)\n",
    "\n",
    "    for cluster in unique_clusters:\n",
    "        cluster_indices = np.where(cluster_labels == cluster)[0]\n",
    "        selected_indices = np.random.choice(cluster_indices, min(\n",
    "            n_examples, len(cluster_indices)), replace=False)\n",
    "\n",
    "        # Mostrar exemplos do cluster\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.suptitle(f\"Cluster {cluster}\", fontsize=16)\n",
    "\n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            plt.subplot(1, n_examples, i + 1)\n",
    "            plt.imshow(all_images[idx])\n",
    "            plt.title(f\"Point {idx}\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(dataset, encoder, subdataset_name):\n",
    "    embeddings = []\n",
    "    dataset_iterator = dataset.unbatch().as_numpy_iterator()\n",
    "    total_images = sum(1 for _ in dataset_iterator)\n",
    "\n",
    "    for image_pair in tqdm(dataset.unbatch(), total=total_images, desc=f\"Extracting Embeddings for {subdataset_name}\"):\n",
    "        embeddings.append(encoder.predict(\n",
    "            image_pair[0][tf.newaxis, ...], verbose=0))\n",
    "\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_clusters(embeddings, max_clusters=10):\n",
    "    from sklearn.metrics import silhouette_score\n",
    "\n",
    "    silhouette_scores = []\n",
    "    for n_clusters in range(2, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(embeddings)\n",
    "        score = silhouette_score(embeddings, cluster_labels)\n",
    "        silhouette_scores.append(score)\n",
    "\n",
    "    optimal_clusters = np.argmax(silhouette_scores) + 2\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(2, max_clusters + 1), silhouette_scores, marker=\"o\")\n",
    "    plt.title(\"Silhouette Score vs. Number of Clusters\")\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.show()\n",
    "\n",
    "    return optimal_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def visualize_tsne(embeddings, cluster_labels, subdataset_name):\n",
    "    # Plot com os clusters\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    unique_labels = np.unique(cluster_labels)\n",
    "    for cluster in unique_labels:\n",
    "        cluster_points = embeddings[cluster_labels == cluster]\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f\"Grupo {\n",
    "                    cluster}\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.title(f\"t-SNE e Clusters\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot sem os clusters\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(embeddings[:, 0], embeddings[:, 1], alpha=0.6)\n",
    "    plt.title(f\"t-SNE\")\n",
    "    plt.xlabel(\"Dimensão 1\")\n",
    "    plt.ylabel(\"Dimensão 2\")\n",
    "    plt.show()\n",
    "\n",
    "def visualize_tsne_3D(embeddings, cluster_labels, subdataset_name):\n",
    "    # Plot com os clusters (3D)\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    unique_labels = np.unique(cluster_labels)\n",
    "    for cluster in unique_labels:\n",
    "        cluster_points = embeddings[cluster_labels == cluster]\n",
    "        ax.scatter(cluster_points[:, 0], cluster_points[:, 1], cluster_points[:, 2],\n",
    "                   label=f\"Grupo {cluster}\", alpha=0.6)\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"t-SNE e Clusters (3D)\")\n",
    "    ax.set_xlabel(\"Dimensão 1\")\n",
    "    ax.set_ylabel(\"Dimensão 2\")\n",
    "    ax.set_zlabel(\"Dimensão 3\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot sem os clusters (3D)\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(embeddings[:, 0], embeddings[:, 1], embeddings[:, 2], alpha=0.6)\n",
    "    ax.set_title(f\"t-SNE (3D)\")\n",
    "    ax.set_xlabel(\"Dimensão 1\")\n",
    "    ax.set_ylabel(\"Dimensão 2\")\n",
    "    ax.set_zlabel(\"Dimensão 3\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(subdataset_path, subdataset_name):\n",
    "    print(f\"Processing subdataset: {subdataset_name}\")\n",
    "\n",
    "    # Carregar o dataset\n",
    "    train_dataset = image_dataset_from_directory(\n",
    "        subdataset_path,\n",
    "        labels=None,\n",
    "        image_size=(Config.imgsz, Config.imgsz),\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True\n",
    "    ).map(lambda x: (x / 255.0, x / 255.0))\n",
    "\n",
    "    # Construir e treinar o autoencoder\n",
    "    autoencoder, encoder = build_autoencoder(\n",
    "        (Config.imgsz, Config.imgsz, 3), Config.encoding_dim)\n",
    "    autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"loss\", patience=Config.patience, restore_best_weights=True\n",
    "    )\n",
    "    autoencoder.fit(train_dataset.repeat(), epochs=Config.epochs,\n",
    "                    steps_per_epoch=len(train_dataset) // Config.batch_size,\n",
    "                    callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Extrair embeddings\n",
    "    embeddings = extract_embeddings(train_dataset, encoder, subdataset_name)\n",
    "\n",
    "    # Encontrar número ótimo de clusters\n",
    "    optimal_clusters = find_optimal_clusters(embeddings)\n",
    "    print(f\"Optimal number of clusters: {optimal_clusters}\")\n",
    "\n",
    "    use_3d = True\n",
    "\n",
    "    # Clusterização e visualização\n",
    "    tsne = TSNE(n_components=3 if use_3d else 2, random_state=42)\n",
    "    tsne_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(tsne_embeddings)\n",
    "\n",
    "    if use_3d:\n",
    "        visualize_tsne_3D(tsne_embeddings, cluster_labels, subdataset_name)\n",
    "    else:\n",
    "        visualize_tsne(tsne_embeddings, cluster_labels, subdataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPUs disponíveis:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iterar sobre os subdatasets\n",
    "subdatasets = [d for d in Config.dataset_path.iterdir() if d.is_dir()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdataset in subdatasets:\n",
    "    process_dataset(subdataset, subdataset.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
