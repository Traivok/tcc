{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import cv2\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model, layers, models\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path setup - Adjust the root directory accordingly\n",
    "cwd = os.getcwd()\n",
    "project_path = pathlib.Path(os.path.join(cwd, \"..\", \"..\")).resolve()\n",
    "splits = ['train', 'valid', 'test']\n",
    "\n",
    "date_str = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    max_trials = 10\n",
    "    experiments_path = os.path.join(cwd, \"..\", \"..\", \"experiments\", \"autoencoder\", date_str)\n",
    "    dataset_path = os.path.join(project_path, \"data\", \"ships_v10i\", \"cropped\")\n",
    "    patience = 5\n",
    "    epochs = 1000\n",
    "    batch_size = 8\n",
    "    encoding_dim = 128\n",
    "    imgsz = 128\n",
    "    use_kmeans = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(Config.experiments_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(input_shape, encoding_dim):\n",
    "    # --- Build the full autoencoder in one continuous pass --- #\n",
    "    inputs = tf.keras.Input(shape=input_shape, name=\"encoder_input\")\n",
    "\n",
    "    # Encoder layers\n",
    "    x = layers.Conv2D(32, (3, 3), activation=\"relu\",\n",
    "                      padding=\"same\", name=\"enc_conv1\")(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\", name=\"enc_pool1\")(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation=\"relu\",\n",
    "                      padding=\"same\", name=\"enc_conv2\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\", name=\"enc_pool2\")(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation=\"relu\",\n",
    "                      padding=\"same\", name=\"enc_conv3\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding=\"same\", name=\"enc_pool3\")(x)\n",
    "\n",
    "    shape_before_flattening = x.shape[1:]  # (H, W, C)\n",
    "    flattened_dim = np.prod(shape_before_flattening)\n",
    "    x = layers.Flatten(name=\"enc_flatten\")(x)\n",
    "    encoded = layers.Dense(encoding_dim, activation=\"relu\", name=\"latent\")(x)\n",
    "\n",
    "    # Decoder layers\n",
    "    x_dec = layers.Dense(flattened_dim, activation=\"relu\",\n",
    "                         name=\"dec_dense\")(encoded)\n",
    "    x_dec = layers.Reshape((shape_before_flattening[0],\n",
    "                            shape_before_flattening[1],\n",
    "                            shape_before_flattening[2]),\n",
    "                           name=\"dec_reshape\")(x_dec)\n",
    "    x_dec = layers.Conv2DTranspose(\n",
    "        128, (3, 3), strides=2, padding=\"same\", activation=\"relu\", name=\"dec_convT1\")(x_dec)\n",
    "    x_dec = layers.Conv2DTranspose(\n",
    "        64, (3, 3), strides=2, padding=\"same\", activation=\"relu\", name=\"dec_convT2\")(x_dec)\n",
    "    x_dec = layers.Conv2DTranspose(\n",
    "        32, (3, 3), strides=2, padding=\"same\", activation=\"relu\", name=\"dec_convT3\")(x_dec)\n",
    "    decoded = layers.Conv2D(3, (3, 3), activation=\"sigmoid\",\n",
    "                            padding=\"same\", name=\"decoder_output\")(x_dec)\n",
    "\n",
    "    # Full autoencoder model\n",
    "    autoencoder = Model(inputs, decoded, name=\"autoencoder_model\")\n",
    "\n",
    "    # --- Extract encoder model ---\n",
    "    # The encoder goes from the original input to the latent representation.\n",
    "    encoder = Model(inputs, encoded, name=\"encoder_model\")\n",
    "\n",
    "    # --- Extract decoder model ---\n",
    "    # The decoder takes latent vectors and reconstructs images.\n",
    "    # We must replicate the decoder path using the same shapes.\n",
    "    latent_inputs = tf.keras.Input(shape=(encoding_dim,), name=\"decoder_input\")\n",
    "    # Rebuild decoder layers separately, in the same order as above:\n",
    "    x_d = autoencoder.get_layer(\"dec_dense\")(latent_inputs)\n",
    "    x_d = autoencoder.get_layer(\"dec_reshape\")(x_d)\n",
    "    x_d = autoencoder.get_layer(\"dec_convT1\")(x_d)\n",
    "    x_d = autoencoder.get_layer(\"dec_convT2\")(x_d)\n",
    "    x_d = autoencoder.get_layer(\"dec_convT3\")(x_d)\n",
    "    decoder_outputs = autoencoder.get_layer(\"decoder_output\")(x_d)\n",
    "    decoder = Model(latent_inputs, decoder_outputs, name=\"decoder_model\")\n",
    "\n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder, decoder  = build_autoencoder(input_shape=(Config.imgsz, Config.imgsz, 3), encoding_dim=Config.encoding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_components = [ (autoencoder, 'autoencoder'), (encoder, 'encoder'), (decoder, 'decoder') ]\n",
    "\n",
    "autoencoder.save(os.path.join(Config.experiments_path, \"autoencoder_no_train.keras\"))\n",
    " \n",
    "for model, name in reversed(model_components):\n",
    "    keras.utils.plot_model(model, to_file=os.path.join(Config.experiments_path, f\"{name}.png\"), show_shapes=True)\n",
    "    keras.utils.plot_model(model, to_file=os.path.join(Config.experiments_path, f\"{name}_no_shapes.png\"), show_shapes=False)\n",
    "\n",
    "    # Print Summary\n",
    "    print(f\"{name} Summary:\")\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderTSNEHyperModel(kt.HyperModel):\n",
    "    def __init__(self, input_shape, train_dataset, steps_per_epoch, experiments_path, use_kmeans=True):\n",
    "        \"\"\"\n",
    "        input_shape: Formato da imagem (H, W, C)\n",
    "        train_dataset: tf.data.Dataset de treino (repetido, sem rótulos)\n",
    "        experiments_path: Caminho base para salvar os resultados do experimento\n",
    "        use_kmeans: Se True, usa K-Means e silhouette_score; caso contrário, usa variância dos embeddings\n",
    "        \"\"\"\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.input_shape = input_shape\n",
    "        self.train_dataset = train_dataset\n",
    "        self.experiments_path = experiments_path\n",
    "        self.use_kmeans = use_kmeans\n",
    "        self.trial = 0\n",
    "        os.makedirs(self.experiments_path, exist_ok=True)\n",
    "\n",
    "    def generate_autoencoder(self, hp, input_shape):\n",
    "        # Define a dimensão do encoding\n",
    "        encoding_dim = hp.Choice('encoding_dim', values=[\n",
    "                                 32, 64, 128, 256, 512])\n",
    "        autoencoder, encoder, decoder = build_autoencoder(\n",
    "            input_shape, encoding_dim)\n",
    "        autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        return autoencoder, encoder, decoder\n",
    "\n",
    "    def build(self, hp):\n",
    "        autoencoder, encoder, decoder = self.generate_autoencoder(\n",
    "            hp, self.input_shape)\n",
    "\n",
    "        # Parâmetros do t-SNE\n",
    "        hp_tsne_components = hp.Choice('tsne_n_components', values=[2])\n",
    "        hp_tsne_perplexity = hp.Int(\n",
    "            'tsne_perplexity', min_value=10, max_value=45, step=5)\n",
    "\n",
    "        # Parâmetros do K-Means (usado apenas se `use_kmeans` for True)\n",
    "        if self.use_kmeans:\n",
    "            hp_n_clusters = hp.Int(\n",
    "                'n_clusters', min_value=2, max_value=15, step=1)\n",
    "            autoencoder.hp_n_clusters = hp_n_clusters\n",
    "\n",
    "        # Armazena os parâmetros no modelo\n",
    "        autoencoder.hp_tsne_components = hp_tsne_components\n",
    "        autoencoder.hp_tsne_perplexity = hp_tsne_perplexity\n",
    "        autoencoder.encoder = encoder\n",
    "        autoencoder.decoder = decoder\n",
    "        return autoencoder\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        # Define caminhos para salvar os resultados\n",
    "        self.trial += 1\n",
    "        trial_path = os.path.join(self.experiments_path, f\"trial_{self.trial}\")\n",
    "        os.makedirs(trial_path, exist_ok=True)\n",
    "\n",
    "        # Treina o autoencoder\n",
    "        history = model.fit(\n",
    "            self.train_dataset,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            epochs=Config.epochs,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Extrai embeddings com o encoder\n",
    "        embeddings = []\n",
    "        for images, _ in self.train_dataset.take(10):  # Processa 10 batches\n",
    "            embeddings.append(model.encoder.predict(images))\n",
    "        embeddings = np.concatenate(embeddings, axis=0)  # Une os embeddings\n",
    "\n",
    "        # Aplica t-SNE nos embeddings\n",
    "        tsne = TSNE(\n",
    "            n_components=model.hp_tsne_components,\n",
    "            perplexity=model.hp_tsne_perplexity,\n",
    "            learning_rate=200,\n",
    "            init='pca',\n",
    "            random_state=42\n",
    "        )\n",
    "        tsne_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "        # Define a métrica\n",
    "        if self.use_kmeans:\n",
    "            # Clustering com K-Means e silhouette_score\n",
    "            n_clusters = model.hp_n_clusters\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            cluster_labels = kmeans.fit_predict(tsne_embeddings)\n",
    "            metric_score = silhouette_score(tsne_embeddings, cluster_labels)\n",
    "            metric_loss = -metric_score  # Otimiza para maximizar o silhouette_score\n",
    "        else:\n",
    "            # Usa a variância dos embeddings como métrica\n",
    "            cluster_labels = None  # Sem K-Means, não há labels\n",
    "            metric_loss = np.std(tsne_embeddings)\n",
    "\n",
    "        # Salva resultados importantes\n",
    "        self.save_results(\n",
    "            trial_path, hp, history, model, tsne_embeddings, cluster_labels, metric_score\n",
    "        )\n",
    "\n",
    "        # Retorna o score calculado (silhouette_score ou variância)\n",
    "        return metric_loss\n",
    "\n",
    "    def save_results(self, trial_path, hp, history, model, tsne_embeddings, cluster_labels, metric_score):\n",
    "        # Salva os modelos\n",
    "        model.encoder.save(os.path.join(trial_path, \"encoder.keras\"))\n",
    "        model.decoder.save(os.path.join(trial_path, \"decoder.keras\"))\n",
    "        model.save(os.path.join(trial_path, \"autoencoder.keras\"))\n",
    "\n",
    "        # Salva os embeddings e rótulos do t-SNE\n",
    "        np.save(os.path.join(trial_path, \"tsne_embeddings.npy\"), tsne_embeddings)\n",
    "        if cluster_labels is not None:\n",
    "            np.save(os.path.join(trial_path, \"cluster_labels.npy\"), cluster_labels)\n",
    "\n",
    "        # Salva o histórico de treinamento\n",
    "        with open(os.path.join(trial_path, \"history.json\"), \"w\") as f:\n",
    "            json.dump(history.history, f)\n",
    "\n",
    "        # Salva os hiperparâmetros\n",
    "        with open(os.path.join(trial_path, \"hyperparameters.json\"), \"w\") as f:\n",
    "            json.dump(hp.values, f)\n",
    "\n",
    "        # Gera visualizações do t-SNE\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        if cluster_labels is not None:\n",
    "            plt.scatter(\n",
    "                tsne_embeddings[:, 0], tsne_embeddings[:, 1], c=cluster_labels, cmap='viridis', s=5)\n",
    "            plt.colorbar(label=\"Cluster Labels\")\n",
    "        else:\n",
    "            plt.scatter(tsne_embeddings[:, 0],\n",
    "                        tsne_embeddings[:, 1], cmap='viridis', s=5)\n",
    "        plt.title(\n",
    "            't-SNE Clustering' if cluster_labels is not None else 't-SNE Embeddings')\n",
    "        plt.xlabel('t-SNE 1')\n",
    "        plt.ylabel('t-SNE 2')\n",
    "        plt.savefig(os.path.join(trial_path, \"tsne_plot.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # Salva o resumo em markdown\n",
    "        self.save_trial_summary(trial_path, hp, metric_score, cluster_labels)\n",
    "\n",
    "    def save_trial_summary(self, trial_path, hp, metric_score, cluster_labels):\n",
    "        summary_path = os.path.join(trial_path, \"trial_summary.md\")\n",
    "        with open(summary_path, \"w\") as f:\n",
    "            f.write(f\"# Trial Summary\\n\")\n",
    "            f.write(f\"**Hiperparâmetros:**\\n\")\n",
    "            for param, value in hp.values.items():\n",
    "                f.write(f\"- {param}: {value}\\n\")\n",
    "            f.write(\n",
    "                f\"\\n**Métrica:** {'Silhouette Score' if cluster_labels is not None else 't-SNE Variance'}: {metric_score:.4f}\\n\")\n",
    "            f.write(f\"\\n## Resultados Salvos\\n\")\n",
    "            f.write(f\"- t-SNE Embeddings: `tsne_embeddings.npy`\\n\")\n",
    "            if cluster_labels is not None:\n",
    "                f.write(f\"- Cluster Labels: `cluster_labels.npy`\\n\")\n",
    "            f.write(f\"- Encoder Model: `encoder/`\\n\")\n",
    "            f.write(f\"- Decoder Model: `decoder/`\\n\")\n",
    "            f.write(f\"- Autoencoder Model: `autoencoder/`\\n\")\n",
    "            f.write(f\"- Training History: `history.json`\\n\")\n",
    "            f.write(f\"- Hyperparameters: `hyperparameters.json`\\n\")\n",
    "            f.write(f\"- t-SNE Plot: `tsne_plot.png`\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset using image_dataset_from_directory\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    Config.dataset_path,\n",
    "    labels=None,  # No labels as this is for autoencoder\n",
    "    image_size=Config.imgsz,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "tuplify = lambda n: (n, n)\n",
    "\n",
    "# Repeat the dataset for uninterrupted training\n",
    "train_dataset = train_dataset.map(lambda x: tuplify(x / 255.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some images from the dataset\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_dataset.take(1):  # Obtém o batch e ignora os rótulos (caso existam)\n",
    "    for i in range(min(4, images.shape[0])):  # Exibe no máximo 9 imagens\n",
    "        plt.subplot(3, 3, i + 1)  # Define a posição no grid (3x3)\n",
    "        plt.imshow((images[i].numpy() * 255).astype(\"uint8\"))  # Exibe cada imagem\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_dataset) // Config.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = AutoencoderTSNEHyperModel(\n",
    "    input_shape=(Config.imgsz, Config.imgsz, 3),\n",
    "    train_dataset=train_dataset.repeat(),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    use_kmeans=Config.use_kmeans,\n",
    "    experiments_path=Config.experiments_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='loss',\n",
    "    max_trials=Config.max_trials,\n",
    "    directory=f'{Config.experiments_path}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autoencoder_results(encoder, decoder, dataset, n_images=10):\n",
    "    \"\"\"\n",
    "    Plota resultados do autoencoder: imagens originais e reconstruídas lado a lado.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i, (images, _) in enumerate(dataset.take(1)):\n",
    "        if i >= n_images:\n",
    "            break\n",
    "        # Pega uma imagem do dataset\n",
    "        original_image = images[i].numpy()\n",
    "        # Reconstrói a imagem com o autoencoder\n",
    "        latent_space = encoder.predict(original_image[np.newaxis, ...])\n",
    "        reconstructed_image = decoder.predict(latent_space)[0]\n",
    "\n",
    "        # Plotar a imagem original\n",
    "        plt.subplot(2, n_images, i + 1)\n",
    "        plt.imshow(original_image)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Plotar a imagem reconstruída\n",
    "        plt.subplot(2, n_images, i + n_images + 1)\n",
    "        plt.imshow(reconstructed_image)\n",
    "        plt.title(\"Reconstruída\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def browse_dataset(dataset, n_images=16):\n",
    "    \"\"\"\n",
    "    Exibe imagens do dataset em uma grade.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, (images, _) in enumerate(dataset.take(1)):\n",
    "        for j in range(min(n_images, len(images))):\n",
    "            plt.subplot(int(n_images ** 0.5), int(n_images ** 0.5), j + 1)\n",
    "            plt.imshow(images[j].numpy())\n",
    "            plt.axis(\"off\")\n",
    "        break\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_examples(tsne_embeddings, cluster_labels, dataset, n_examples_per_cluster=5):\n",
    "    \"\"\"\n",
    "    Mostra exemplos de imagens para cada cluster gerado pelo K-Means.\n",
    "    \"\"\"\n",
    "    clusters = np.unique(cluster_labels)\n",
    "    cluster_indices = {cluster: [] for cluster in clusters}\n",
    "    \n",
    "    # Mapeia as imagens dos embeddings para os clusters\n",
    "    for i, label in enumerate(cluster_labels):\n",
    "        if len(cluster_indices[label]) < n_examples_per_cluster:\n",
    "            cluster_indices[label].append(i)\n",
    "\n",
    "    # Carrega todas as imagens em um array para fácil acesso\n",
    "    all_images = []\n",
    "    for images, _ in dataset.unbatch().take(len(cluster_labels)):\n",
    "        all_images.append(images.numpy())\n",
    "    all_images = np.array(all_images)\n",
    "\n",
    "    # Plota exemplos de cada cluster\n",
    "    for cluster, indices in cluster_indices.items():\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        for i, index in enumerate(indices):\n",
    "            plt.subplot(1, n_examples_per_cluster, i + 1)\n",
    "            plt.imshow(all_images[index])\n",
    "            plt.title(f\"Cluster {cluster}\")\n",
    "            plt.axis(\"off\")\n",
    "        plt.suptitle(f\"Exemplos do Cluster {cluster}\", fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo os melhores hiperparâmetros\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Construindo o melhor modelo com os melhores hiperparâmetros\n",
    "best_model = hypermodel.build(best_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir imagens originais e reconstruídas\n",
    "plot_autoencoder_results(best_model.encoder, best_model.decoder, train_dataset, n_images=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Navegar pelo dataset\n",
    "browse_dataset(train_dataset, n_images=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def find_best_trial(experiments_path):\n",
    "    best_trial = None\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for trial_dir in os.listdir(experiments_path):\n",
    "        print(trial_dir)\n",
    "        trial_path = os.path.join(experiments_path, trial_dir)\n",
    "        if os.path.isdir(trial_path) and trial_dir.startswith(\"trial_\"):\n",
    "            print(f\"Checking {trial_path}\")\n",
    "            # Load the metric score for the trial\n",
    "            metric_file = os.path.join(trial_path, \"history.json\")  # Or \"history.json\" if it's stored there\n",
    "            try:\n",
    "                with open(metric_file, \"r\") as f:\n",
    "                    losses_array = json.load(f)\n",
    "                    print(losses_array)\n",
    "                    loss = np.min(losses_array['loss']) \n",
    "                    if loss is not None and loss < best_loss:\n",
    "                        best_loss = loss\n",
    "                        best_trial = trial_path\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Metric file not found in {trial_path}\")\n",
    "    return best_trial, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the function\n",
    "best_trial_path, best_metric = find_best_trial(os.path.join(Config.experiments_path))\n",
    "\n",
    "if best_trial_path:\n",
    "    print(f\"Best trial: {best_trial_path}, Best Metric: {best_metric}\")\n",
    "else:\n",
    "    print(\"No trials found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_trial_path and Config.use_kmeans:\n",
    "    tsne_embeddings = np.load(os.path.join(\n",
    "        best_trial_path, \"tsne_embeddings.npy\"))\n",
    "    cluster_labels = np.load(os.path.join(\n",
    "        best_trial_path, \"cluster_labels.npy\"))\n",
    "\n",
    "    plot_cluster_examples(\n",
    "        tsne_embeddings=tsne_embeddings,\n",
    "        cluster_labels=cluster_labels,\n",
    "        dataset=train_dataset,\n",
    "        n_examples_per_cluster=5\n",
    "    )\n",
    "else:\n",
    "    print(\"No best trial found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
